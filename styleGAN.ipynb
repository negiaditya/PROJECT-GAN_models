{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"styleGAN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMk6d2as+NfzZ6O6nZMQySd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"0z07KdVOetZX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"39af1d77-d7f3-4289-e7a2-7219adfbbd65","executionInfo":{"status":"ok","timestamp":1591878010526,"user_tz":-330,"elapsed":6449,"user":{"displayName":"Aditya Negi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKLQvIg3xrYZPsW_GbG94SfbG3G1so88qj49LhrQ=s64","userId":"00873376449291213595"}}},"source":["!pip install tensorflow_gan"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorflow_gan\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/2e/62922111d7d50e1900e3030764743ea7735540ce103b3ab30fd5cd2d8a2b/tensorflow_gan-2.0.0-py2.py3-none-any.whl (365kB)\n","\r\u001b[K     |█                               | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 368kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-probability>=0.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gan) (0.10.0)\n","Requirement already satisfied: tensorflow-hub>=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gan) (0.8.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow_gan) (1.12.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow_gan) (4.4.2)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow_gan) (1.18.5)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow_gan) (0.3.3)\n","Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow_gan) (1.3.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub>=0.2->tensorflow_gan) (3.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub>=0.2->tensorflow_gan) (47.1.1)\n","Installing collected packages: tensorflow-gan\n","Successfully installed tensorflow-gan-2.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jvNYoH9Q11hI","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from google.cloud import storage\n","        \n","from tensorflow.keras.layers import Conv2D, Dense, AveragePooling2D, LeakyReLU, Activation,Layer\n","from tensorflow.keras.layers import Reshape, UpSampling2D, Dropout, Flatten, Input, add, Cropping2D\n","from tensorflow.keras.models import Model,model_from_json\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.optimizers import Adam"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yc2EIG-meNt6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"d024991c-8ea9-4a88-aa19-58eb05160b9f","executionInfo":{"status":"ok","timestamp":1591878014577,"user_tz":-330,"elapsed":1258,"user":{"displayName":"Aditya Negi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKLQvIg3xrYZPsW_GbG94SfbG3G1so88qj49LhrQ=s64","userId":"00873376449291213595"}}},"source":["\n","from tensorflow.keras.callbacks import TensorBoard\n","\n","import tensorflow_datasets as tfds\n","import tensorflow_gan as tfgan\n","\n","from functools import partial\n","\n","import numpy as np\n","import json\n","from PIL import Image"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pQj080Ibuag5","colab_type":"text"},"source":["# Discriminator model"]},{"cell_type":"code","metadata":{"id":"TvkugCTyuieQ","colab_type":"code","colab":{}},"source":["def dis_block(_input,filters,pool=True):\n","  #convolutional layer\n","  x=Conv2D(filters=filters,kernel_size=3,padding='same',kernel_initializer='he_normal',bias_initializer='zeros')(_input)\n","  #leaky relu activation\n","  x=LeakyReLU(0.01)(x)\n","  #add pooling layer\n","  if pool:\n","    x=AveragePooling2D()(x)\n","  #convolutional layer\n","  x=Conv2D(filters=filters,kernel_size=3,padding='same',kernel_initializer='he_normal',bias_initializer='zeros')(x)\n","  #leaky relu activation\n","  x=LeakyReLU(0.01)(x)\n","  return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-lOXUFccwmq6","colab_type":"code","colab":{}},"source":["def _discriminator(img_size):\n","  inp=Input(shape=[img_size,img_size,3])\n","  x=dis_block(inp,16)\n","  x=dis_block(x,32)\n","  x=dis_block(x,64)\n","\n","  if img_size>32:\n","    x=dis_block(x,128)\n","  if img_size>64:\n","    x=dis_block(x,192)\n","  if img_size>128:\n","    x=dis_block(x,256)\n","  if img_size>256:\n","    x=dis_block(x,384)\n","  if img_size>512:\n","    x=dis_block(x,512)\n","\n","  x=Flatten()(x)\n","  x=Dense(128,kernel_initializer='he_normal',bias_initializer='zeros')(x)\n","  x=LeakyReLU(0.01)(x)\n","\n","  x=Dropout(0.01)(x)\n","  x=Dense(1,kernel_initializer='he_normal',bias_initializer='zeros')(x)\n","\n","  return Model(inputs=inp,outputs=x)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nrQ33JucNM9r","colab_type":"text"},"source":["# Adaptive Instance normalization\n","Used to incorporate style vector "]},{"cell_type":"markdown","metadata":{"id":"GIJSb4ymOgdL","colab_type":"text"},"source":["![alt text](https://miro.medium.com/max/3858/1*tmzVhW0gs0KQnSX-RDPbUg.png)"]},{"cell_type":"code","metadata":{"id":"GpitgZODztoL","colab_type":"code","colab":{}},"source":["class AdaInstanceNormalization(Layer):\n","  \n","  def __init__(self,axis=-1,momentum=0.99,epsilon=1e-3,center=True,scale=True,**kwargs):\n","    super(AdaInstanceNormalization,self).__init__(**kwargs)\n","    self.axis=axis\n","    self.momentum=momentum\n","    self.epsilon=epsilon\n","    self.center=center\n","    self.scale=scale\n","\n","  def build(self,input_shape):\n","    super(AdaInsranceNormalization,self).build(input_shape)\n","\n","  def call(self,inputs,training=None):\n","    input_shape=K.int_shape(inputs[0])\n","    reduction_axes=list(range(0,len(input_shape)))\n","\n","    beta=inputs[1]\n","    gamma=inputs[2]\n","\n","    if self.axis is not None:\n","      del reduction_axes[self.axis]\n","    \n","    del reduction_axes[0]\n","    mean=K.mean(inputs[0],reduction_axes,keepdims=True)\n","    stddev=K.std(inputs[0],reduction_axes,keepdims=True) +self.epsilon\n","    normed= (inputs[0]-mean) / stddev\n","\n","  def get_config(self):\n","    config= {\n","        'axis':self.axis,\n","        'momentum':self.momentum,\n","        'epsilon':self.epsilon,\n","        'center':self.center,\n","        'scale':self.scale\n","    }\n","    base_config=super(AdaInstanceNormalization,self).get_config()\n","    return dict(list(base_config.items())+ list(config.itmes()))\n","\n","  def compute_output_shape(self,input_shape):\n","    return input_shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Z10ca24No8m","colab_type":"text"},"source":["# Generator model\n"]},{"cell_type":"code","metadata":{"id":"pw3dZjdPNKZO","colab_type":"code","colab":{}},"source":["def gen_block(_input,style,noise,filters,up=True):\n","  s=Dense(filters,kernel_initializer='he_normal',bias_initializer='ones')(style)\n","  s=Reshape([1,1,filters])(s)\n","  b=Dense(filters,kernel_initializer='he_normal',bias_initializer='zeros')(style)\n","  b=Reshape([1,1,filters])(b)\n","  \n","  n=Conv2D(filters=filters,kernel_size=1,padding='same',kernel_initializer='zeros',bias_initializer='zeros')(noise)\n","\n","  if up:\n","    out=UpSampling2D(interpolation='bilinear')(_input)\n","    out=Conv2D(filters=filters,kernel_size=3,padding='same',kernel_initializer='he_normal',bias_initializer='zeros')(out)\n","  else:\n","    out=Conv2D(filters=filters,kernel_size=3,padding='same',kernel_initializer='he_normal',bias_initializer='zeros')(out)\n","  \n","  out=add([out,n])\n","\n","  out=AdaInstanceNormalization()([out,s,b])\n","\n","  out=LeakyReLU(0.01)(out)\n","\n","  s=Dense(filters,kernel_initializer='he_normal',bias_initializer='ones')(style)\n","  s=Reshape([1,1,filters])(s)\n","  s=Dense(filters,kernel_initializer='he_normal',bias_initializer='ones')(style)\n","  s=Reshape([1,1,filters])(s)\n","\n","  n=Conv2D(filters=filters,kernel_size=1,padding='same',kernel_initializer='zeros',bias_initializer='zeros')(noise)\n","\n","  out=Conv2D(filters=filters,kernel_size=3,padding='same',kernel_initializer='he_normal',bias_initializer='zeros')(out)\n","\n","  out=add([out,n])\n","\n","  out=AdaInstanceNormalization()([out,s,b])\n","\n","  out=LeakyReLU(0.01)(out)\n","\n","  return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XzSgmvKgUkFS","colab_type":"code","colab":{}},"source":["def _generator(img_size):\n","  latents=[]\n","  _size=img_size\n","  while _size>=4:\n","    latents.append(Input(shape=[512]))\n","    _size=_size/2\n","\n","  style_layers=len(latents)\n","\n","  input_noise=Input(shape=[img_size,img_size,1])\n","  noise=[Activation('linear')(input_noise)]\n","  cur_size=img_size\n","  while cur_size>4:\n","    cur_size= cur_size//2\n","    noise.append(Cropping2D(int(cur_size/2)))(noise[-1])\n","\n","  inp=Input(shape=[1])\n","  x=Dense(4*4*img_size,kernel_initializer='ones',bias_initializer='zerps')(inp)\n","  x=Reshape([4,4,img_size])(x)\n","  x=gen_block(x,latents[0],noise[-1],img_size,up=False)\n","\n","  if img_size>=1024:\n","    x=gen_block(x,latents[-8],noise[7],512)\n","  if img_size>=512:\n","    x=gen_block(x,latents[-7],noise[6],384)\n","  if img_size>=256:\n","    x=gen_block(x,latents[-6],noise[5],256)\n","  if img_size>=128:\n","    x=gen_block(x,latents[-5],noise[4],512)\n","  if img_size>=64:\n","    x=gen_block(x,latents[-4],noise[3],128)\n","\n","  x=gen_block(x,latents[-3],noise[2],64)\n","  x=gen_block(x,latents[-2],noise[1],32)\n","  x=gen_block(x,latents[-1],noise[0],16)\n","\n","  x=Conv2D(filters=3,kenrel_size=1,padding='same',activation='sigmoid',bias_initializer='zeros')(x)\n","\n","  return style_layers,Model(inputs= latents+[input_noise,inp],outputs=x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f-9_HxKhYqjm","colab_type":"text"},"source":["# Style mapping"]},{"cell_type":"code","metadata":{"id":"PGv89RrhYiw7","colab_type":"code","colab":{}},"source":["def _style_mapping(latent_size=512,layers=6):\n","  inp=Input(shape=[latent_size])\n","\n","  x=Dense(512,kernel_initializer='he_normal',bias_initializer='zeros')(inp)\n","\n","  for _ in range(layers-1):\n","    x=LeakyReLU(0.01)(X)\n","    x=Dense(512,kernel_initializer='he_normal',bias_initializer='zeros')(x)\n","\n","  return Model(inputs=inp,outputs=x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D1lZ05MBe1Ef","colab_type":"text"},"source":["# Main program"]},{"cell_type":"markdown","metadata":{"id":"b1JHw7TafGGN","colab_type":"text"},"source":["### r1/r2 gradient penalty"]},{"cell_type":"code","metadata":{"id":"R9h5Qfw5ZMWz","colab_type":"code","colab":{}},"source":["def gradient_penalty_loss(y_true,y_pred,averaged_samples,weight,sample_weight=None):\n","  \n","  gradients=K.gradients(y_pred,averaged_samples)[0]\n","  gradients_sqr=K.square(gradients)\n","  gradients_penalty=K.sum(gradients_sqr,axis=np.arange(1,len(gradients_sqr.shape)))\n","  \n","  # weight * ||grad||^2\n","  # Penalize the gradient norm \n","  return K.mean(gradient_penalty *weight)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UVl0nid4aXE_","colab_type":"text"},"source":["### safeDownload amd safeUpload"]},{"cell_type":"code","metadata":{"id":"TZws9sZoai1A","colab_type":"code","colab":{}},"source":["def safeDownload(addr):\n","    _comps=addr.split('/')\n","    comps=[]\n","    for k in _comps:\n","        if len(k)>0:\n","            comps.append(k)\n","    if comps[0]==\"gs:\":\n","        client=storage.Client(project=\"deep-learning-capstone-course\")\n","        bucket=client.get_bucket(comps[1])\n","        blob=storage.Blob(\"/\".join(comps[2:]),bucket)\n","        with open(\"img_bucket/\"+\"/\".join(comps[2:]),'w') as file:\n","            client.download_blob_to_file(blob,file) \n","\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrRsMw5Jdwgm","colab_type":"code","colab":{}},"source":["def safeUpload(addr):\n","    _comps=addr.split('/')\n","    comps=[]\n","    for k in _comps:\n","        if len(k)>0:\n","            comps.append(k)\n","\n","    if comps[0]==\"gs:\":\n","        client=storage.Client(project=\"deep-learning-capstone-course\")\n","        bucket=client.get_bucket(comps[1])\n","        blob=storage.Blob(\"/\".join(comps[2:]),bucket)\n","        blob.upload_from_filename(\"img_bucket/\"+\"/\".join(comps[2:]),client=client)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vSCwJjITgvCo","colab_type":"text"},"source":["### GAN implementation "]},{"cell_type":"code","metadata":{"id":"AZ8lrYbSgT6T","colab_type":"code","colab":{}},"source":["class GAN(object):\n","  def __init__(self,img_size=1024,batch_size=8,latent_size=512,latent_layers=4,steps=0, lr=0.0001,decay=0.00001,preTrained=False,bucket=\"image-bucket\"):\n","    temp=(1-decay)**steps\n","    self.lr=lr*temp\n","    self.steps=steps\n","    self.img_size=img_size\n","    self.latent_size=latent_size\n","    self.latent_layers=latent_layers\n","    self.batch_size=batch_size\n","    self.bucket=bucket\n","\n","    ss=img_size\n","    self.style_layers=0\n","    while ss>2:\n","      ss //=2\n","      self.style_layers+=1\n","\n","    self._gen,self._styler,self._dis=None,None,None\n","    self.single_gen,self.single_sty,self.single_dis=None,None,None\n","    self.mix_gen,self.mix_sty,self.mix_dis=None,None,None\n","    \n","    if not preTrained:\n","      self.singleGen()\n","      self.singleStyle()\n","      self.singleDis()\n","      self.mixGen()\n","      self.mixStyle()\n","      self.mixDis()\n","    else:\n","      self.loadAll()\n","\n","  def gen(self):\n","    if self._gen==None:\n","      self.style_layers,self._gen=_generator (self.img_size)\n","      print(\"Generator:\")\n","      self._gen.summary()\n","    return self._gen\n","  \n","  def styler(self):\n","    if self._styler==None:\n","      self._styler=_style_mapping(latent_size=self.latent_size,layers=self.latent_layers)\n","      print(\"Styler:\")\n","      self._styler.summary()\n","    return self._styler\n","\n","  def dis(self):\n","    if self._dis==None:\n","      self.dis=_discriminator(self.img_size)\n","      print(\"Discriminator:\")\n","      self._dis.summary()\n","    return self._dis\n","\n","  def singleGen(self):\n","    if self.single_gen==None:\n","      self.dis().trainable= False\n","      for layer in self.dis().layers:\n","        layer.trainable=False\n","      \n","      self.gen().trainable=True\n","      for layer in self.gen().layers:\n","        layer.trainable=True\n","\n","      self.styler().trainable=False\n","      for layer in self.styler().layers:\n","        layer.trainable=False\n","\n","      latent_inp=Input(shape=[self.latent_size])\n","      latents=self.styler()(latent_inp)\n","      const_inp=Input(shape=[self.img_size,self.img_size,1])\n","      const_1_inp=Input(shape=[1])\n","\n","      gen_out=self.gen()([latents]*self.style_layers + [const_inp,const_1_inp])\n","      dis_out=self.dis()(gen_out)\n","\n","      self.single_gen=Model(inputs=[latent_inp,const_inp,const_1_inp],outputs=dis_out)\n","      self.single_gen.compile(optimizer=Adam(self.lr,beta_1=0,beta_2=0.99,decay=0.00001),loss='mse')\n","    return self.single_gen\n","\n","  def singleStyle(self):\n","      if self.single_sty==None:\n","          self.dis().trainable=False\n","          for layer in self.dis().layers:\n","              layer.trainable=False\n","\n","          self.gen().trainable=False\n","          for layer in self.gen().layers:\n","              layer.trainable=False\n","\n","          self.styler().trainable=True\n","          for layer in self.styler().layers:\n","              layer.trainable=True\n","\n","          latent_inp=Input(shape=[self.latent_size])\n","          latents=self.styler()(latent_inp)\n","          const_inp=Input(shape=[self.img_size,self.img_size,1])\n","          const_1_inp=Input(shape=[1])\n","\n","          gen_out=self.gen()([latents]*self.style_layers + [const_inp,const_1_inp])\n","          dis_out=self.dis()(gen_out)\n","\n","          self.single_sty = Model(inputs = [latent_inp,const_inp,const_1_inp], outputs = dis_out)\n","          self.single_sty.compile(optimizer = Adam(self.lr*0.01, beta_1 = 0, beta_2 = 0.99, decay = 0.00001), loss = 'mse')\n","      return self.single_sty\n","\n","  def singleDis(self):\n","    if self.single_dis==None:\n","      self.dis().trainable=True\n","      for layer in self.dis().layers:\n","        layer.trainable=True\n","\n","      self.gen().trainable=False\n","      for layer in self.gen().layers:\n","        layer.trainable=False\n","\n","      self.styler().trainable=False\n","      for layer in self.styler().layers:\n","        layer.trainable=False\n","\n","      real_inp=Input(shape=[self.img_size,self.img_size,3])\n","      dout_real=self.dis()(real_inp)\n","\n","      latent_inp=Input(shape=[self.latent_size])\n","      latents=self.styler()(latent_inp)\n","      const_inp=Input(shape=[self.img_size,self.img_size,1])\n","      const_1_inp=Input(shape=[1])\n","\n","      gen_out=self.gen()([latents]*self.style_layers + [const_inp,const_1_inp])\n","      dout_fake=self.dis()(gen_out)\n","\n","      partial_gp_loss=partial(gradient_penalty_loss,averaged_samples=real_inp,weight=50)\n","\n","      self.single_dis= Model(inputs=[real_inp,latent_inp,const_inp,const_1_inp],outputs=[dout_real,dout_fake,dout_real])\n","      self.single_dis.compile(optimizer=Adam(self.lr,beta_1=0,beta_2=0.99,decay=0.00001),loss=['mse','mse',partial_gp_loss]) \n","    return self.single_dis\n","\n","    def mixGen(self):\n","      if self.mix_gen==None:\n","        self.dis().trainable=False\n","        for layer in self.dis().layers:\n","          layer.trainable=False\n","\n","        self.gen().trainable=True\n","        for layer in self.gen().layers:\n","          layer.trainable=True\n","\n","        self.styler().trainable=False\n","        for layer in self.styler().layers:\n","          layer.trainable=False\n","\n","        latents_inp=[]\n","        latents=[]\n","        for _ in range(self.style_layers):\n","          latents_inp.append(Input(shape=[self.latent_size]))\n","          latents.append(self.styler()(latents_inp[-1]))\n","\n","        const_inp=Input(shape=[self.img_size,self.img_size,1])\n","        const_1_inp=Input(shape=[1])\n","\n","        gen_out=self.gen()(latents+[const_inp,const_1_inp])\n","        dis_out=self.dis()(gen_out)\n","\n","        self.mix_gen= Model(inputs=latents_inp+[const_inp,const_1_inp],outputs=dis_out)\n","        self.mix_gen.compile(optimizer=Adam(self.lr,beta_1=0,beta_2=0.99,decay=0.00001),loss=['mse']) \n","      return self.mix_gen\n","\n","    def mixStyle(self):\n","      if self.mix_sty==None:\n","        self.dis().trainable=False\n","        for layer in self.dis().layers:\n","          layer.trainable=False\n","\n","        self.gen().trainable=False\n","        for layer in self.gen().layers:\n","          layer.trainable=False\n","\n","        self.styler().trainable=True\n","        for layer in self.styler().layers:\n","          layer.trainable=True\n","\n","        latents_inp=[]\n","        latents=[]\n","        \n","        for _ in range(self.style_layers):\n","          latents_inp.append(Input(shape=[self.latent_size]))\n","          latents.append(self.styler()(latents_inp[-1]))\n","\n","        const_inp=Input(shape=[self.img_size,self.img_size,1])\n","        const_1_inp=Input(shape=[1])\n","\n","        gen_out=self.gen()(latents+[const_inp,const_1_inp])\n","        dis_out=self.dis()(gen_out)\n","\n","        self.mix_sty= Model(inputs=latents_inp + [const_inp,const_1_inp], outputs=dis_out)\n","        self.mix_sty.compile(optimizer=Adam(self.lr,beta_1=0,beta_2=0.99,decay=0.00001),loss=['mse']) \n","      return self.mix_gen\n","\n","    def mixDis(self):\n","      if self.simgle_dis==None:\n","        self.dis().trainable=True\n","        for layer in self.dis().layers:\n","          layer.trainable=True\n","\n","        self.gen().trainable=False\n","        for layer in self.gen().layers:\n","          layer.trainable=False\n","\n","        self.styler().trainable=False\n","        for layer in self.styler().layers:\n","          layer.trainable=False\n","\n","        real_inp=Input(shape=[self.img_size,self.img_size,3])\n","        dout_real=self.dis()(real_inp)\n","\n","        for _ in range(self.style_layers):\n","          latents_inp.append(Input(shape=[self.latent_size]))\n","          latents.append(self.styler()(latents_inp[-1])) \n","        \n","        const_inp=Input(shape=[self.img_size,self.img_size,1])\n","        const_1_inp=Input(shape=[1])\n","\n","        gen_out=self.gen()(latents + [const_inp,const_1_inp])\n","        dout_fake=self.dis()(gen_out)\n","\n","        partial_gp_loss=partial(gradient_penalty_loss,averaged_samples=real_inp,weight=50)\n","\n","        self.mix_dis= Model(inputs=[real_inp]+latents_inp+[const_inp,const_1_inp],outputs=[dout_real,dout_fake,dout_real])\n","        self.mix_dis.compile(optimizer=Adam(self.lr,beta_1=0,beta_2=0.99,decay=0.00001),loss=['mse','mse',partial_gp_loss]) \n","      return self.mix_dis\n","\n","    def _saveModel(self,model,name):\n","        _bucket=self.bucket if self.bucket[:3]!=\"gs:\" else \"img_bucket\"\n","        _json=model.to_json()\n","        f=open(\"{0}/stylegan_model/{1}.json\".format(_bucket,name),'w')\n","        f.write(_json)\n","        f.close()\n","        model.save_weights(\"{0}/stylegan_model/{1}_{2}.h5\".format(_bucket,name,self.steps))\n","        safeUpload(\"{0}/stylegan_model/{1}.json\".format(_bucket,name))\n","        safeUpload(\"{0}/stylegan_model/{1}_{2}.h5\".format(_bucket,name,self.steps))\n","\n","    def _loadModel(self,name,steps):\n","        _bucket=self.bucket if self.bucket[:3]!=\"gs:\" else \"img_bucker\"\n","        safeDownload(\"{0}/stylegan_model/{1}.json\".format(self.bucket,name))\n","        safeDownload(\"{0}/stylegan_model/{1}_{2}.h5\".format(self.bucket,name,steps))\n","  \n","        f=open(\"{0}/stylegan_model/{1}.json\".format(_bucket,name),'r')\n","        _json=f.read()\n","        f.close()\n","        \n","        mod=model_from_json(str(_json),custom_objects={'AdaInstanceNormalization':AdaInstanceNormalization})\n","        mod.load_weights(\"{0}/stylegan_model/{1}_{2}.h5\".format(_bucket,name,steps))\n","\n","        return mod\n","\n","    def saveAll(self):\n","        print(\"Saving model for step {0}.\".format(self.steps))\n","        self._saveModel(self.gen(),\"gen\")\n","        self._saveModel(self.styler(),\"styler\")\n","        self._saveModel(self.dis(),\"dis\")\n","\n","    def loadAll(self):\n","        self._gen = self._loadModel(\"gen\",self.steps)\n","        self._styler = self._loadModel(\"styler\",self.steps)\n","        self._dis = self._loadModel(\"dis\",self.steps)\n","\n","    def saveGenerated(self,img):\n","        _bucket = self.bucket if self.bucket[:3]!=\"gs:\" else \"img_bucket\"\n","        img = Image.fromarray(np.uint8(img*255),mode = 'RGB')\n","        img.save(\"{0}/generated_images/{1}.jpg\".format(_bucket,self.steps))\n","        safeUpload(\"{0}/generated_images/{1}.jpg\".format(self.bucket,self.steps))    \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BftIjxmqhGk7","colab_type":"text"},"source":["## TRAIN the model"]},{"cell_type":"code","metadata":{"id":"oBd7AEfaX-FZ","colab_type":"code","colab":{}},"source":["def train_forever(gan,ds,show_fn=None):\n","    tb=TensorBoard(log_dir=\"{0}/tf_logs\".format(gan.bucket),batch_size=8)\n","    ones=np.ones((8,1),dtype=np.float32)\n","    onesEval=np.ones((gan.style_layers*3,1),dtype=np.float32)\n","    zeros=np.zeros((8,1),dtype=np.float32)\n","    zerosEval=np.zeros((gan.style_layers*3,1),dtype=np.float32)\n","    nones= -ones\n","    nonesEval= -onesEval\n","    g_losses,d_losses= [],[]\n","\n","    while True:\n","        if gan.steps % 10 < 5:\n","            g1=gan.singleGen().train_on_batch([np.random.normal(size=[8,gan.latent_size]),np.random.uniform(size=[8,gan.img_size,gan.img_size,1]),ones],ones)\n","            g2=gan.singleStyle().train_on_batch([np.random.normal(size=[8,gan.latent_size]),np.random.uniform(size=[8,gan.img_size,gan.img_size,1]),ones],ones)\n","            dis_data=[next(iter(ds)),np.random.normal(size=[8,gan.latent_size]),np.random.uniform(size=[8,gan.img_size,gan.img_size,1]),ones]\n","            d=gan.singleDis().train_on_batch(dis_data,[ones,nones,ones])\n","        else:\n","            n1,n2=[],[]\n","            threshold1=np.int32(np.random.unifor(0.0,gan.style_layers,size=[8]))\n","            threshold2=np.int32(np.random.uniform(0.0,gan.style_layers,size=[8]))\n","            _n1=np.random.normal(size=[8,gan.latent_size])\n","            _n2=np.random.normal(size=[8,gan.latent_size])\n","            _n3=np.random.normal(size=[8,gan.latent_size])\n","            _n4=np.random.normal(size=[8,gan.latent_size])\n","            for i in range(gan.style_layers):\n","                n1back,n2back=[],[]\n","                for j in range(8):\n","                    if i<threshold1[j]:\n","                        n1back.append(_n1[j])\n","                    else:\n","                        n1back.append(_n2[j])\n","                    if i<threshold2[j]:\n","                        n2back.append(_n3[j])\n","                    else:\n","                        n2back.append(_n4[j])\n","                n1back=np.array(n1back)\n","                n2back=np.array(n2back)\n","                n1.append(n1back)\n","                n2.append(n2back)\n","            g1=gan.mixGen().train_on_batch(n1+[np.random.uniform(size=[8,gan.img_size,gan.img_size,1]),ones],ones)\n","            g2=gan.mixStyle().train_on_batch(n1+[np.random.unifrom(size=[8,gan.img_size,gan.img_size,1]),ones],ones)\n","            d=gan.mixDis().train_on_batch([next(iter(ds))] + n2 + [np.random.uniform(size=[8,gan.img_size,gan.img_size,1]),ones],[ones,nones,ones])\n","        tb.on_epoch_end(gan.steps,{\"gen_loss\":g,\"dis_loss0\":d[0],\"dis_loss1\":d[1],\"dis_loss2\":d[2]})\n","        if gan.steps%11==0:\n","            print(\"At step {0},generator loss: {1},discriminator loss: {2}.\".format(gan.steps,[g1,g2],d))\n","        d_losses.append(d)\n","        g_losses.append([g1,g2])\n","        gan.steps += 1\n","        if gan.steps%1000==0:\n","            _n1,_n2=np.random.normal(size=[gan.style_layers,gan.latent_size]),np.random.normal(size=[gan.style_layers,gan.latent_size])\n","            latents=[]\n","            for i in range(gan.style_layers):\n","                nn=[]\n","                for j in range(gan.style_layers):\n","                    nn.append(_n1[j])\n","                for j in range(gan.style_layers):\n","                    nn.append(_n2[j])\n","                for j in range(gan.style_layers):\n","                    if j<=i:\n","                        nn.append(_n1[j])\n","                    else:\n","                        nn.append(_n2[j])\n","                nn=np.array(nn)\n","                latents.append(gan.styler().predict(nn))\n","            \n","            images=gan.gen().predict(latents+[np.random.uniform(size = [gan.style_layers*3,gan.img_size,gan.img_size,1]),onesEval])\n","            image_grid=tfgan.eval.python_image_grid(images,grid_shape=(3,gan.style_layers))\n","            \n","            if show_fn!=None:\n","                show_fn(image_grid)\n","            gan.saveGenerated(image_grid)\n","            gan.saveAll()\n","            \n","            if gan.bucket[:3]==\"gs:\":\n","                _bucket_addr = \"img_bucket\"\n","            rf = open(\"{0}/records/{1}_g.txt\".format(_bucket_addr,gan.steps),'w')\n","            for dd in d_losses:\n","                rf.write(\"{0}\\n\".format(dd))\n","            rf.close()\n","            safeUpload(\"{0}/records/{1}_g.txt\".format(gan.bucket,gan.steps))\n","            rf2 = open(\"{0}/records/{1}_d.txt\".format(_bucket_addr,gan.steps),'w')\n","            for gg in g_losses:\n","                rf2.write(\"{0} \".format(gg))\n","                rf2.write(\"\\n\")\n","            rf2.close()\n","            d_losses,g_losses = [],[]\n","            safeUpload(\"{0}/records/{1}_d.txt\".format(gan.bucket,gan.steps))\n","            "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JWT4OJlL3jMb","colab_type":"text"},"source":["# Predict the values "]},{"cell_type":"code","metadata":{"id":"SMxdov0f3NQS","colab_type":"code","colab":{}},"source":["def _predict(gan,show_fn=None):\n","    onesEval=np.ones((1,1),dtype=np.float32)\n","    n1=np.random.normal(size,[1,gan.latent_size])\n","    latents=[]\n","    for i in range(gan.style_layers):\n","        latents.append(gan.styler().predict(n1))\n","    print(latents[0])\n","    images=gan.gen().predict(latents+[np.random.uniform(size=[1,gan.img_size,gan.img_size,1]),onesEval])\n","    images_grid=tfgan.eval.python_image_grid(images,grid_shape=(1,1))\n","    if show_fn!=None:\n","        show_fn(image_grid)\n","    #gan.saveGenerated(image_grid)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZmDedL255p8L","colab_type":"text"},"source":["# Preprocess and train"]},{"cell_type":"code","metadata":{"id":"ngPw2TJ75nO9","colab_type":"code","colab":{}},"source":["def _preprocess(element):\n","    images=(tf.cast(element['image'],tf.float32))/255.0\n","    return images\n","                    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"emSOMfMl58f8","colab_type":"code","colab":{}},"source":["def main():\n","    gan=GAN(img_size=256,lr=0.0001,steps=3000,preTrained=True)\n","    dataset_dir=\"{0}/datasets\".format(\"gs://face-images-ece655\")\n","    ds=tfds.load('celeb_a_hq/256',split='train',data_dir=dataset_dir).map(_preprocess,num_parallel_calls=4).repeat().shuffle(buffer_size=1000).batch(8)\n","    ds=tfds.as_numpy(ds)\n","    train_forever(gan,ds)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ao-Mh2LC684D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":303},"outputId":"ca1b2d42-5436-4e85-80c2-9c5bedce09e4","executionInfo":{"status":"error","timestamp":1591888360290,"user_tz":-330,"elapsed":949,"user":{"displayName":"Aditya Negi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKLQvIg3xrYZPsW_GbG94SfbG3G1so88qj49LhrQ=s64","userId":"00873376449291213595"}}},"source":["main()"],"execution_count":45,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-41-f0da1b552e72>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreTrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdataset_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"{0}/datasets\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gs://face-images-ece655\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'celeb_a_hq/256'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-44-5a23a7c90bf6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_size, batch_size, latent_size, latent_layers, steps, lr, decay, preTrained, bucket)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixDis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'GAN' object has no attribute 'loadAll'"]}]},{"cell_type":"code","metadata":{"id":"CsG3pjx-693j","colab_type":"code","colab":{}},"source":[" "],"execution_count":0,"outputs":[]}]}